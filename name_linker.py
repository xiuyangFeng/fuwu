"""
äººç‰©å§“åä¸ä¸ªäººä¸»é¡µé“¾æ¥åŒ¹é…å™¨

ä¸»è¦åŠŸèƒ½ï¼š
1. åŠ è½½ name_output.txt æ–‡ä»¶ä¸­çš„äººç‰©å§“åå’Œä¸»é¡µé“¾æ¥æ•°æ®
2. åœ¨æ–‡æœ¬ä¸­æ™ºèƒ½è¯†åˆ«å’ŒåŒ¹é…äººç‰©å§“å
3. ä¸ºåŒ¹é…åˆ°çš„äººç‰©æä¾›ä¸»é¡µé“¾æ¥
4. æ”¯æŒä¸­è‹±æ–‡å§“åçš„æ™ºèƒ½åŒ¹é…å’Œå»é‡
"""

import logging
import re
from typing import Dict, List, Set, Optional
from pathlib import Path
from dataclasses import dataclass
import jieba

logger = logging.getLogger(__name__)

@dataclass(frozen=True, eq=True)
class PersonInfo:
    """äººç‰©ä¿¡æ¯æ•°æ®ç»“æ„"""
    id: int
    name: str
    homepage_url: Optional[str]
    name_variations: frozenset  # ä½¿ç”¨frozensetä»¥æ”¯æŒhashable

class NameLinker:
    """
    äººç‰©å§“åä¸ä¸ªäººä¸»é¡µé“¾æ¥åŒ¹é…å™¨
    æ”¯æŒé«˜æ•ˆçš„å§“åè¯†åˆ«å’Œé“¾æ¥åŒ¹é…
    """
    
    def __init__(self, file_path: str = "name_output.txt"):
        self.file_path = Path(file_path)
        self.persons: List[PersonInfo] = []
        self.name_to_person: Dict[str, PersonInfo] = {}
        self.name_variations: Dict[str, PersonInfo] = {}  # åŒ…å«å§“åå˜ä½“çš„æ˜ å°„
        self.loaded = False
        
        # å¸¸è§çš„å­¦æœ¯å¤´è¡”å’ŒèŒä½ï¼Œç”¨äºæ¸…ç†å§“å
        self.academic_titles = {
            'æ•™æˆ', 'å‰¯æ•™æˆ', 'åŠ©æ•™æˆ', 'è®²å¸ˆ', 'ç ”ç©¶å‘˜', 'å‰¯ç ”ç©¶å‘˜', 'åŠ©ç†ç ”ç©¶å‘˜',
            'åšå£«', 'ç¡•å£«', 'é™¢å£«', 'ä¸»ä»»', 'å‰¯ä¸»ä»»', 'æ‰€é•¿', 'å‰¯æ‰€é•¿', 'ä¸»ä»»åŒ»å¸ˆ',
            'å‰¯ä¸»ä»»åŒ»å¸ˆ', 'ä¸»æ²»åŒ»å¸ˆ', 'ä½é™¢åŒ»å¸ˆ', 'æ•™æˆ', 'Prof', 'Dr', 'PhD'
        }
    
    def load_name_data(self, file_path: Optional[str] = None) -> bool:
        """
        ä»æŒ‡å®šæ–‡ä»¶åŠ è½½å§“åå’Œä¸»é¡µURLæ•°æ®
        
        Args:
            file_path: å¯é€‰çš„æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨åˆå§‹åŒ–æ—¶çš„è·¯å¾„
            
        Returns:
            bool: åŠ è½½æ˜¯å¦æˆåŠŸ
        """
        if self.loaded:
            return True
            
        target_file = Path(file_path) if file_path else self.file_path
        if not target_file.exists():
            logger.warning(f"äººç‰©å§“åæ•°æ®æ–‡ä»¶ {target_file} ä¸å­˜åœ¨ï¼Œäººç‰©ä¸»é¡µé“¾æ¥åŠŸèƒ½å°†ä¸å¯ç”¨")
            return False
        
        try:
            with open(target_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # è§£ææ–‡ä»¶å†…å®¹
            self.persons = self._parse_name_file(content)
            
            # æ„å»ºå¿«é€ŸæŸ¥è¯¢ç´¢å¼•
            self._build_name_indexes()
            
            self.loaded = True
            logger.info(f"æˆåŠŸåŠ è½½ {len(self.persons)} ä¸ªäººç‰©æ•°æ®ï¼Œå…¶ä¸­ {len([p for p in self.persons if p.homepage_url])} ä¸ªæœ‰ä¸»é¡µé“¾æ¥")
            return True
            
        except Exception as e:
            logger.error(f"åŠ è½½äººç‰©å§“åæ•°æ®å¤±è´¥: {e}")
            return False
    
    def _parse_name_file(self, content: str) -> List[PersonInfo]:
        """
        è§£æ name_output.txt æ–‡ä»¶æ ¼å¼
        
        é¢„æœŸæ ¼å¼ï¼š
        ç¼–å·.å§“å
        ä¸ªäººä¸»é¡µåœ°å€ï¼šURL
        (ç©ºè¡Œ)
        """
        persons = []
        
        # ä½¿ç”¨æ›´ç²¾ç¡®çš„æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
        pattern = r'(\d+)\.(.+?)\nä¸ªäººä¸»é¡µåœ°å€ï¼š(.*?)\n'
        matches = re.findall(pattern, content, re.MULTILINE | re.DOTALL)
        
        for match in matches:
            entry_id, raw_name, raw_url = match
            
            # æ¸…ç†å§“å
            name = self._clean_name(raw_name.strip())
            
            # æ¸…ç†URL
            url = raw_url.strip() if raw_url.strip() else None
            
            # å¦‚æœURLä¸ºç©ºæˆ–è€…æ— æ•ˆï¼Œè®¾ç½®ä¸ºNone
            if url and not self._is_valid_url(url):
                url = None
            
            # ç”Ÿæˆå§“åå˜ä½“
            name_variations = self._generate_name_variations(name)
            
            person = PersonInfo(
                id=int(entry_id),
                name=name,
                homepage_url=url,
                name_variations=frozenset(name_variations)
            )
            
            persons.append(person)
        
        return persons
    
    def _clean_name(self, name: str) -> str:
        """æ¸…ç†å§“åï¼Œç§»é™¤å¤´è¡”å’Œå¤šä½™çš„ç©ºæ ¼"""
        cleaned = name.strip()
        
        # ç§»é™¤å¸¸è§çš„å­¦æœ¯å¤´è¡”
        for title in self.academic_titles:
            if cleaned.endswith(title):
                cleaned = cleaned[:-len(title)].strip()
            elif cleaned.startswith(title):
                cleaned = cleaned[len(title):].strip()
        
        # ç§»é™¤å¤šä½™çš„ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
        cleaned = re.sub(r'\s+', ' ', cleaned)
        cleaned = cleaned.strip('.,ï¼Œã€‚')
        
        return cleaned
    
    def _is_valid_url(self, url: str) -> bool:
        """æ£€æŸ¥URLæ˜¯å¦æœ‰æ•ˆ"""
        if not url:
            return False
        return url.startswith(('http://', 'https://')) and len(url) > 10
    
    def _generate_name_variations(self, name: str) -> Set[str]:
        """ç”Ÿæˆå§“åçš„å„ç§å˜ä½“å½¢å¼ï¼Œæé«˜åŒ¹é…å‡†ç¡®ç‡"""
        variations = {name}
        
        # æ·»åŠ å»é™¤ç©ºæ ¼çš„ç‰ˆæœ¬
        variations.add(name.replace(' ', ''))
        
        # å¦‚æœåŒ…å«ç©ºæ ¼ï¼Œæ·»åŠ å„ç§ç©ºæ ¼å˜ä½“
        if ' ' in name:
            # ä¸­æ–‡å§“åçš„è‹±æ–‡å˜ä½“å¤„ç†
            parts = name.split()
            if len(parts) == 2:
                # å§“åå€’ç½®ï¼ˆå¦‚ï¼šZhang Wei -> Wei Zhangï¼‰
                variations.add(f"{parts[1]} {parts[0]}")
                # å§“åè¿æ¥ï¼ˆå¦‚ï¼šZhang Wei -> ZhangWeiï¼‰
                variations.add(f"{parts[0]}{parts[1]}")
        
        # å¤„ç†ä¸­æ–‡å§“åçš„å¸¸è§å˜ä½“
        if self._is_chinese_name(name):
            # æ·»åŠ å¯èƒ½çš„è‹±æ–‡æ‹¼éŸ³å˜ä½“ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
            variations.add(name.replace('Â·', '').replace('â€¢', ''))
        
        return variations
    
    def _is_chinese_name(self, name: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºä¸­æ–‡å§“å"""
        chinese_chars = sum(1 for char in name if '\u4e00' <= char <= '\u9fff')
        return chinese_chars > 0
    
    def _build_name_indexes(self):
        """æ„å»ºå§“åæŸ¥è¯¢ç´¢å¼•"""
        self.name_to_person.clear()
        self.name_variations.clear()
        
        for person in self.persons:
            # ä¸»è¦å§“åæ˜ å°„
            self.name_to_person[person.name] = person
            
            # æ‰€æœ‰å˜ä½“æ˜ å°„
            for variation in person.name_variations:
                self.name_variations[variation] = person
        
        logger.debug(f"æ„å»ºäº† {len(self.name_to_person)} ä¸ªä¸»è¦å§“åå’Œ {len(self.name_variations)} ä¸ªå§“åå˜ä½“çš„ç´¢å¼•")
    
    def find_mentioned_names(self, text: str, include_all: bool = False) -> Dict[str, str]:
        """
        åœ¨ç»™å®šæ–‡æœ¬ä¸­æŸ¥æ‰¾æ‰€æœ‰æåˆ°çš„äººç‰©å§“åï¼Œå¹¶è¿”å›å…¶ä¸»é¡µé“¾æ¥
        
        Args:
            text: è¦æœç´¢çš„æ–‡æœ¬
            include_all: æ˜¯å¦åŒ…å«æ²¡æœ‰ä¸»é¡µé“¾æ¥çš„äººç‰©
        
        Returns:
            Dict[str, str]: ä¸€ä¸ªå­—å…¸ï¼Œé”®æ˜¯æ‰¾åˆ°çš„å§“åï¼Œå€¼æ˜¯å¯¹åº”çš„ä¸»é¡µURLï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        """
        if not self.loaded or not text:
            return {}
        
        found_names = {}
        text_lower = text.lower()
        
        # ä½¿ç”¨ä¼˜åŒ–çš„åŒ¹é…ç­–ç•¥ï¼šå…ˆç²¾ç¡®åŒ¹é…ï¼Œå†æ¨¡ç³ŠåŒ¹é…
        matched_persons = set()
        
        # 1. ç²¾ç¡®åŒ¹é…æ‰€æœ‰å§“åå˜ä½“
        for name_variation, person in self.name_variations.items():
            if self._is_name_mentioned(text, name_variation):
                matched_persons.add(person)
        
        # 2. æ„å»ºç»“æœå­—å…¸
        for person in matched_persons:
            # å¦‚æœä¸åŒ…å«æ²¡æœ‰é“¾æ¥çš„äººç‰©ï¼Œä¸”è¯¥äººç‰©æ²¡æœ‰é“¾æ¥ï¼Œåˆ™è·³è¿‡
            if not include_all and not person.homepage_url:
                continue
                
            # ä½¿ç”¨åŸå§‹å§“åä½œä¸ºé”®
            found_names[person.name] = person.homepage_url
        
        logger.debug(f"åœ¨æ–‡æœ¬ä¸­æ‰¾åˆ° {len(found_names)} ä¸ªæœ‰é“¾æ¥çš„äººç‰©å§“å")
        return found_names
    
    def _is_name_mentioned(self, text: str, name: str) -> bool:
        """
        åˆ¤æ–­å§“åæ˜¯å¦åœ¨æ–‡æœ¬ä¸­è¢«æåŠ
        ä½¿ç”¨æ™ºèƒ½åŒ¹é…ç­–ç•¥ï¼Œé¿å…è¯¯åŒ¹é…
        """
        if not name or not text:
            return False
        
        # ç®€åŒ–åŒ¹é…ç­–ç•¥ï¼šå¯¹äºä¸­æ–‡å§“åï¼Œç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸²åŒ…å«åŒ¹é…
        # è¿™æ ·æ›´é€‚åˆä¸­æ–‡æ–‡æœ¬çš„ç‰¹ç‚¹
        try:
            # å¯¹äºé•¿åº¦å°äºç­‰äº2çš„å§“åï¼Œä½¿ç”¨æ›´ä¸¥æ ¼çš„åŒ¹é…
            if len(name) <= 2:
                # ç¡®ä¿å§“åå‰åä¸æ˜¯ä¸­æ–‡å­—ç¬¦ï¼ˆé¿å…è¯¯åŒ¹é…ï¼‰
                pattern = r'(?<!\u4e00-\u9fff)' + re.escape(name) + r'(?!\u4e00-\u9fff)'
                return bool(re.search(pattern, text))
            else:
                # å¯¹äºè¾ƒé•¿çš„å§“åï¼ˆåŒ…æ‹¬è‹±æ–‡å§“åï¼‰ï¼Œç›´æ¥ä½¿ç”¨å­å­—ç¬¦ä¸²åŒ¹é…
                return name in text
                
        except re.error:
            # å¦‚æœæ­£åˆ™è¡¨è¾¾å¼æœ‰é—®é¢˜ï¼Œå›é€€åˆ°ç®€å•çš„å­å­—ç¬¦ä¸²åŒ¹é…
            return name in text
    
    def get_person_info(self, name: str) -> Optional[PersonInfo]:
        """
        æ ¹æ®å§“åè·å–äººç‰©ä¿¡æ¯
        
        Args:
            name: äººç‰©å§“å
            
        Returns:
            Optional[PersonInfo]: äººç‰©ä¿¡æ¯ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
        """
        if not self.loaded:
            return None
        
        # é¦–å…ˆåœ¨ä¸»è¦å§“åä¸­æŸ¥æ‰¾
        if name in self.name_to_person:
            return self.name_to_person[name]
        
        # ç„¶ååœ¨å˜ä½“ä¸­æŸ¥æ‰¾
        if name in self.name_variations:
            return self.name_variations[name]
        
        return None
    
    def format_person_links_markdown(self, mentioned_names: Dict[str, str]) -> str:
        """
        å°†æ‰¾åˆ°çš„äººç‰©å§“åå’Œé“¾æ¥æ ¼å¼åŒ–ä¸ºç¾è§‚çš„Markdownæ ¼å¼
        
        Args:
            mentioned_names: find_mentioned_namesè¿”å›çš„ç»“æœ
            
        Returns:
            str: æ ¼å¼åŒ–åçš„Markdownå­—ç¬¦ä¸²
        """
        if not mentioned_names:
            return ""
        
        # è¿‡æ»¤å‡ºæœ‰æœ‰æ•ˆé“¾æ¥çš„äººç‰©
        valid_links = {name: url for name, url in mentioned_names.items() if url and self._is_valid_url(url)}
        
        if not valid_links:
            return ""
        
        # ç»Ÿä¸€æ ·å¼ï¼šæ— è®ºå•ä¸ªè¿˜æ˜¯å¤šä¸ªï¼Œéƒ½ä½¿ç”¨ä¸€è‡´çš„æ ¼å¼ï¼Œå¹¶åœ¨é“¾æ¥ä¸­åµŒå…¥äººç‰©å§“åä¿¡æ¯
        if len(valid_links) == 1:
            # å•ä¸ªäººç‰©é“¾æ¥ï¼šä½¿ç”¨ä¸å¤šä¸ªé“¾æ¥ä¸€è‡´çš„æ ¼å¼
            name, url = next(iter(valid_links.items()))
            markdown = f"\n\n---\n\nğŸ‘¤ **ç›¸å…³äººç‰©ä¸»é¡µ** (1ä¸ª)\n\n"
            # åœ¨é“¾æ¥æ–‡æœ¬ä¸­æ˜ç¡®åŒ…å«å§“åä¿¡æ¯ï¼Œä¾¿äºå‰ç«¯æå–
            markdown += f"1ï¸âƒ£ **{name}** - [ç‚¹å‡»è®¿é—®{name}çš„ä¸ªäººä¸»é¡µ]({url})\n"
        else:
            # å¤šä¸ªäººç‰©é“¾æ¥ï¼šåˆ—è¡¨å¼æ˜¾ç¤º
            markdown = f"\n\n---\n\nğŸ‘¥ **ç›¸å…³äººç‰©ä¸»é¡µ** ({len(valid_links)}ä¸ª)\n\n"
            for i, (name, url) in enumerate(valid_links.items(), 1):
                # ç¡®ä¿æ¯ä¸ªé“¾æ¥éƒ½ä½¿ç”¨å®Œå…¨ç›¸åŒçš„æ ¼å¼ï¼Œåœ¨é“¾æ¥æ–‡æœ¬ä¸­åŒ…å«å§“å
                markdown += f"{i}ï¸âƒ£ **{name}** - [ç‚¹å‡»è®¿é—®{name}çš„ä¸ªäººä¸»é¡µ]({url})\n"
        
        return markdown
    
    def format_person_links_html_enhanced(self, mentioned_names: Dict[str, str]) -> str:
        """
        å°†æ‰¾åˆ°çš„äººç‰©å§“åå’Œé“¾æ¥æ ¼å¼åŒ–ä¸ºç¾è§‚çš„HTMLæ ¼å¼ï¼ˆç”¨äºå‰ç«¯ç‰¹æ®Šå¤„ç†ï¼‰
        
        Args:
            mentioned_names: find_mentioned_namesè¿”å›çš„ç»“æœ
            
        Returns:
            str: æ ¼å¼åŒ–åçš„HTMLå­—ç¬¦ä¸²
        """
        if not mentioned_names:
            return ""
        
        # è¿‡æ»¤å‡ºæœ‰æœ‰æ•ˆé“¾æ¥çš„äººç‰©
        valid_links = {name: url for name, url in mentioned_names.items() if url and self._is_valid_url(url)}
        
        if not valid_links:
            return ""
        
        html = """
<div class="person-links-container">
    <div class="person-links-header">
        <span class="person-links-icon">ğŸ‘¤</span>
        <span class="person-links-title">ç›¸å…³äººç‰©ä¸»é¡µ</span>
        <span class="person-links-count">{count}ä¸ª</span>
    </div>
    <div class="person-links-list">
""".format(count=len(valid_links))
        
        for name, url in valid_links.items():
            # æå–åŸŸåç”¨äºæ˜¾ç¤º
            domain = self._extract_domain(url)
            html += f'''
        <div class="person-link-item">
            <div class="person-link-info">
                <span class="person-name">{name}</span>
                <span class="person-domain">{domain}</span>
            </div>
            <a href="{url}" target="_blank" rel="noopener noreferrer" class="person-link-btn">
                <span class="person-link-icon">ğŸ”—</span>
                è®¿é—®ä¸»é¡µ
            </a>
        </div>
'''
        
        html += """
    </div>
</div>"""
        
        return html
    
    def _extract_domain(self, url: str) -> str:
        """ä»URLä¸­æå–åŸŸå"""
        try:
            import urllib.parse
            parsed = urllib.parse.urlparse(url)
            domain = parsed.netloc
            # ç§»é™¤wwwå‰ç¼€
            if domain.startswith('www.'):
                domain = domain[4:]
            return domain
        except:
            return "æœªçŸ¥åŸŸå"
    
    def get_statistics(self) -> Dict:
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        if not self.loaded:
            return {"loaded": False}
        
        total_persons = len(self.persons)
        persons_with_links = len([p for p in self.persons if p.homepage_url])
        
        return {
            "loaded": True,
            "total_persons": total_persons,
            "persons_with_links": persons_with_links,
            "link_coverage": persons_with_links / total_persons if total_persons > 0 else 0,
            "total_name_variations": len(self.name_variations)
        }

# åˆ›å»ºå…¨å±€å®ä¾‹
name_linker = NameLinker()
